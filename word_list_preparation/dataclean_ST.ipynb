{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18ca6350-2510-45ad-98ca-a93593c0247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packeges:\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer \n",
    "import kagglehub\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "#Model to extract class of words\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Model for embedding\n",
    "ST_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#ST_model = SentenceTransformer('all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a1e763-0700-4958-80d4-597fcc176634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedding:\n",
    "\n",
    "def embedding_function(word):\n",
    "    embedded_word = ST_model.encode(word)\n",
    "    return embedded_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d66830f4-51b9-4d32-ab96-8a34f44528ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of words\n",
    "with open(\"data/large_word_list.txt\", 'r') as file:\n",
    "    word_list = [line.strip() for line in file]  # Remove trailing newlines and spaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04349423-6460-42b7-840d-d8e151f5ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec794ee7-09ab-4871-a26b-b57a7b33a770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracts the nouns and reduces words to base form\n",
    "nouns = []\n",
    "\n",
    "for word in word_list:\n",
    "    doc = nlp(word)  \n",
    "    for token in doc:  # Iterate through tokens in the processed word\n",
    "        word_base = token.lemma_  # Extractz the base form \n",
    "        pos_tag = token.pos_  # Extract word class tag\n",
    "        if pos_tag == \"NOUN\":\n",
    "            nouns.append(word_base)  # Append to nouns if it's a noun\n",
    "\n",
    "# Removes dublicates from list:\n",
    "nouns = list(set(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a40c3901-fca3-4b40-bdd6-a8067a48e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b051aa35-9625-4843-abb4-52efca880c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding all the nouns and adding both embeddings and word to lists\n",
    "\n",
    "embeddings = []\n",
    "embedded_words = []\n",
    "\n",
    "for word in nouns:\n",
    "    try:\n",
    "        current_embedded_word = ST_model.encode(word)\n",
    "        embeddings.append(current_embedded_word)\n",
    "        embedded_words.append(word)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping word: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ebffd4-6e97-4065-8b27-c8877e1a2a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 closest words with cosine similarity:\n",
      "groundwater: 0.8155\n",
      "soil: 0.4909\n",
      "geology: 0.4371\n",
      "drainage: 0.4343\n",
      "irrigation: 0.4282\n",
      "earth: 0.4258\n",
      "ground: 0.4239\n",
      "precipitation: 0.4133\n",
      "fountain: 0.3675\n",
      "basin: 0.3658\n",
      "Top word is: soil\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Embed the target words\n",
    "word1 = \"groundwater\"\n",
    "word2 = \"earth\"\n",
    "\n",
    "combined_embedding = word1 + \" and \" + word2 + \" combinned\"\n",
    "combined_embedding = embedding_function(combined_embedding)\n",
    "\n",
    "#embedding1 = embedding_function(word1)\n",
    "#embedding2 = embedding_function(word2)\n",
    "\n",
    "# Normalize individual embeddings\n",
    "#embedding1 = embedding1 / np.linalg.norm(embedding1)\n",
    "#embedding2 = embedding2 / np.linalg.norm(embedding2)\n",
    "\n",
    "# Combine embeddings with normalization\n",
    "#combined_embedding = embedding1 + embedding2\n",
    "#combined_embedding = combined_embedding / np.linalg.norm(combined_embedding)\n",
    "\n",
    "# Compute cosine similarities with filtered embeddings\n",
    "similarities = cosine_similarity([combined_embedding], embeddings)\n",
    "\n",
    "# Sort indices to get top 10 matches\n",
    "sorted_indices = np.argsort(similarities[0])[::-1][:10]  # Top 10 matches\n",
    "\n",
    "# Retrieve the top words and their corresponding similarity scores\n",
    "top_words = [embedded_words[i] for i in sorted_indices]\n",
    "top_similarities = [similarities[0][i] for i in sorted_indices]\n",
    "\n",
    "# Print results with cosine similarity\n",
    "print(\"Top 10 closest words with cosine similarity:\")\n",
    "for word, similarity in zip(top_words, top_similarities):\n",
    "    print(f\"{word}: {similarity:.4f}\")\n",
    "\n",
    "if top_words[0] not in [word1, word2]:\n",
    "    top_word = top_words[0]\n",
    "elif top_words[1] not in [word1, word2]:\n",
    "    top_word = top_words[1]\n",
    "else:\n",
    "    top_word = top_words[2]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Top word is: {top_word}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d20e6f8-c713-4064-ae21-5ec37a396ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save word\n",
    "np.save(\"embedded_words_ST.npy\", embedded_words)\n",
    "np.save(\"embeddings_ST.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8b2706-bf73-4da6-b842-f3504bfaae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf901c2e-f95a-419e-a569-207da8843f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df = pd.read_csv(\"data/full_emoji.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db1a3ed-ddec-4544-8bce-7f6f36953a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list = emoji_df['emoji'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "878bd193-0fe0-4199-a5aa-635b016a5393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['😁', '😆', '😅', '🤣', '😂', '🙂', '🙃', '😉', '😊', '😇', '🥰', '😍', '🤩', '😘', '😗', '☺', '😚', '😙', '🥲', '😋', '😛', '😜', '🤪', '😝', '🤑', '🤗', '🤭', '🤫', '🤔', '🤐', '🤨', '😐', '😑', '😶', '😶\\u200d🌫️', '😏', '😒', '🙄', '😬', '😮\\u200d💨', '🤥', '😌', '😔', '😪', '🤤', '😴', '😷', '🤒', '🤕', '🤢', '🤮', '🤧', '🥵', '🥶', '🥴', '😵', '😵\\u200d💫', '🤯', '🤠', '🥳', '🥸', '😎', '🤓', '🧐', '😕', '😟', '🙁', '☹', '😮', '😯', '😲', '😳', '🥺', '😦', '😧', '😨', '😰', '😥', '😢', '😭', '😱', '😖', '😣', '😞', '😓', '😩', '😫', '🥱', '😤', '😡', '😠', '🤬', '😈', '👿', '💀', '☠', '💩', '🤡', '👹', '👺', '👻', '👽', '👾', '🤖', '😺', '😸', '😹', '😻', '😼', '😽', '🙀', '😿', '😾', '🙈', '🙉', '🙊', '💋', '💌', '💘', '💝', '💖', '💗', '💓', '💞', '💕', '💟', '❣', '💔', '❤️\\u200d🔥', '❤️\\u200d🩹', '❤', '🧡', '💛', '💚', '💙', '💜', '🤎', '🖤', '🤍', '💯', '💢', '💥', '💫', '💦', '💨', '🕳', '💣', '💬', '👁️\\u200d🗨️', '🗨', '🗯', '💭', '💤', '👋', '🤚', '🖐', '✋', '🖖', '👌', '🤌', '🤏', '✌', '🤞', '🤟', '🤘', '🤙', '👈', '👉', '👆', '🖕', '👇', '☝', '👍', '👎', '✊', '👊', '🤛', '🤜', '👏', '🙌', '👐', '🤲', '🤝', '🙏', '✍', '💅', '🤳', '💪', '🦾', '🦿', '🦵', '🦶', '👂', '🦻', '👃', '🧠', '🫀', '🫁', '🦷', '🦴', '👀', '👁', '👅', '👄', '👶', '🧒', '👦', '👧', '🧑', '👱', '👨', '🧔', '🧔\\u200d♂️', '🧔\\u200d♀️', '👨\\u200d🦰', '👨\\u200d🦱', '👨\\u200d🦳', '👨\\u200d🦲', '👩', '👩\\u200d🦰', '🧑\\u200d🦰', '👩\\u200d🦱', '🧑\\u200d🦱', '👩\\u200d🦳', '🧑\\u200d🦳', '👩\\u200d🦲', '🧑\\u200d🦲', '👱\\u200d♀️', '👱\\u200d♂️', '🧓', '👴', '👵', '🙍', '🙍\\u200d♂️', '🙍\\u200d♀️', '🙎', '🙎\\u200d♂️', '🙎\\u200d♀️', '🙅', '🙅\\u200d♂️', '🙅\\u200d♀️', '🙆', '🙆\\u200d♂️', '🙆\\u200d♀️', '💁', '💁\\u200d♂️', '💁\\u200d♀️', '🙋', '🙋\\u200d♂️', '🙋\\u200d♀️', '🧏', '🧏\\u200d♂️', '🧏\\u200d♀️', '🙇', '🙇\\u200d♂️', '🙇\\u200d♀️', '🤦', '🤦\\u200d♂️', '🤦\\u200d♀️', '🤷', '🤷\\u200d♂️', '🤷\\u200d♀️', '🧑\\u200d⚕️', '👨\\u200d⚕️', '👩\\u200d⚕️', '🧑\\u200d🎓', '👨\\u200d🎓', '👩\\u200d🎓', '🧑\\u200d🏫', '👨\\u200d🏫', '👩\\u200d🏫', '🧑\\u200d⚖️', '👨\\u200d⚖️', '👩\\u200d⚖️', '🧑\\u200d🌾', '👨\\u200d🌾', '👩\\u200d🌾', '🧑\\u200d🍳', '👨\\u200d🍳', '👩\\u200d🍳', '🧑\\u200d🔧', '👨\\u200d🔧', '👩\\u200d🔧', '🧑\\u200d🏭', '👨\\u200d🏭', '👩\\u200d🏭', '🧑\\u200d💼', '👨\\u200d💼', '👩\\u200d💼', '🧑\\u200d🔬', '👨\\u200d🔬', '👩\\u200d🔬', '🧑\\u200d💻', '👨\\u200d💻', '👩\\u200d💻', '🧑\\u200d🎤', '👨\\u200d🎤', '👩\\u200d🎤', '🧑\\u200d🎨', '👨\\u200d🎨', '👩\\u200d🎨', '🧑\\u200d✈️', '👨\\u200d✈️', '👩\\u200d✈️', '🧑\\u200d🚀', '👨\\u200d🚀', '👩\\u200d🚀', '🧑\\u200d🚒', '👨\\u200d🚒', '👩\\u200d🚒', '👮', '👮\\u200d♂️', '👮\\u200d♀️', '🕵', '🕵️\\u200d♂️', '🕵️\\u200d♀️', '💂', '💂\\u200d♂️', '💂\\u200d♀️', '🥷', '👷', '👷\\u200d♂️', '👷\\u200d♀️', '🤴', '👸', '👳', '👳\\u200d♂️', '👳\\u200d♀️', '👲', '🧕', '🤵', '🤵\\u200d♂️', '🤵\\u200d♀️', '👰', '👰\\u200d♂️', '👰\\u200d♀️', '🤰', '🤱', '👩\\u200d🍼', '👨\\u200d🍼', '🧑\\u200d🍼', '👼', '🎅', '🤶', '🧑\\u200d🎄', '🦸', '🦸\\u200d♂️', '🦸\\u200d♀️', '🦹', '🦹\\u200d♂️', '🦹\\u200d♀️', '🧙', '🧙\\u200d♂️', '🧙\\u200d♀️', '🧚', '🧚\\u200d♂️', '🧚\\u200d♀️', '🧛', '🧛\\u200d♂️', '🧛\\u200d♀️', '🧜', '🧜\\u200d♂️', '🧜\\u200d♀️', '🧝', '🧝\\u200d♂️', '🧝\\u200d♀️', '🧞', '🧞\\u200d♂️', '🧞\\u200d♀️', '🧟', '🧟\\u200d♂️', '🧟\\u200d♀️', '💆', '💆\\u200d♂️', '💆\\u200d♀️', '💇', '💇\\u200d♂️', '💇\\u200d♀️', '🚶', '🚶\\u200d♂️', '🚶\\u200d♀️', '🧍', '🧍\\u200d♂️', '🧍\\u200d♀️', '🧎', '🧎\\u200d♂️', '🧎\\u200d♀️', '🧑\\u200d🦯', '👨\\u200d🦯', '👩\\u200d🦯', '🧑\\u200d🦼', '👨\\u200d🦼', '👩\\u200d🦼', '🧑\\u200d🦽', '👨\\u200d🦽', '👩\\u200d🦽', '🏃', '🏃\\u200d♂️', '🏃\\u200d♀️', '💃', '🕺', '🕴', '👯', '👯\\u200d♂️', '👯\\u200d♀️', '🧖', '🧖\\u200d♂️', '🧖\\u200d♀️', '🧗', '🧗\\u200d♂️', '🧗\\u200d♀️', '🤺', '🏇', '⛷', '🏂', '🏌', '🏌️\\u200d♂️', '🏌️\\u200d♀️', '🏄', '🏄\\u200d♂️', '🏄\\u200d♀️', '🚣', '🚣\\u200d♂️', '🚣\\u200d♀️', '🏊', '🏊\\u200d♂️', '🏊\\u200d♀️', '⛹', '⛹️\\u200d♂️', '⛹️\\u200d♀️', '🏋', '🏋️\\u200d♂️', '🏋️\\u200d♀️', '🚴', '🚴\\u200d♂️', '🚴\\u200d♀️', '🚵', '🚵\\u200d♂️', '🚵\\u200d♀️', '🤸', '🤸\\u200d♂️', '🤸\\u200d♀️', '🤼', '🤼\\u200d♂️', '🤼\\u200d♀️', '🤽', '🤽\\u200d♂️', '🤽\\u200d♀️', '🤾', '🤾\\u200d♂️', '🤾\\u200d♀️', '🤹', '🤹\\u200d♂️', '🤹\\u200d♀️', '🧘', '🧘\\u200d♂️', '🧘\\u200d♀️', '🛀', '🛌', '🧑\\u200d🤝\\u200d🧑', '👭', '👫', '👬', '💏', '👩\\u200d❤️\\u200d💋\\u200d👨', '👨\\u200d❤️\\u200d💋\\u200d👨', '👩\\u200d❤️\\u200d💋\\u200d👩', '💑', '👩\\u200d❤️\\u200d👨', '👨\\u200d❤️\\u200d👨', '👩\\u200d❤️\\u200d👩', '👪', '👨\\u200d👩\\u200d👦', '👨\\u200d👩\\u200d👧', '👨\\u200d👩\\u200d👧\\u200d👦', '👨\\u200d👩\\u200d👦\\u200d👦', '👨\\u200d👩\\u200d👧\\u200d👧', '👨\\u200d👨\\u200d👦', '👨\\u200d👨\\u200d👧', '👨\\u200d👨\\u200d👧\\u200d👦', '👨\\u200d👨\\u200d👦\\u200d👦', '👨\\u200d👨\\u200d👧\\u200d👧', '👩\\u200d👩\\u200d👦', '👩\\u200d👩\\u200d👧', '👩\\u200d👩\\u200d👧\\u200d👦', '👩\\u200d👩\\u200d👦\\u200d👦', '👩\\u200d👩\\u200d👧\\u200d👧', '👨\\u200d👦', '👨\\u200d👦\\u200d👦', '👨\\u200d👧', '👨\\u200d👧\\u200d👦', '👨\\u200d👧\\u200d👧', '👩\\u200d👦', '👩\\u200d👦\\u200d👦', '👩\\u200d👧', '👩\\u200d👧\\u200d👦', '👩\\u200d👧\\u200d👧', '🗣', '👤', '👥', '🫂', '👣', '🦰', '🦱', '🦳', '🦲', '🐵', '🐒', '🦍', '🦧', '🐶', '🐕', '🦮', '🐕\\u200d🦺', '🐩', '🐺', '🦊', '🦝', '🐱', '🐈', '🐈\\u200d⬛', '🦁', '🐯', '🐅', '🐆', '🐴', '🐎', '🦄', '🦓', '🦌', '🦬', '🐮', '🐂', '🐃', '🐄', '🐷', '🐖', '🐗', '🐽', '🐏', '🐑', '🐐', '🐪', '🐫', '🦙', '🦒', '🐘', '🦣', '🦏', '🦛', '🐭', '🐁', '🐀', '🐹', '🐰', '🐇', '🐿', '🦫', '🦔', '🦇', '🐻', '🐻\\u200d❄️', '🐨', '🐼', '🦥', '🦦', '🦨', '🦘', '🦡', '🐾', '🦃', '🐔', '🐓', '🐣', '🐤', '🐥', '🐦', '🐧', '🕊', '🦅', '🦆', '🦢', '🦉', '🦤', '🪶', '🦩', '🦚', '🦜', '🐸', '🐊', '🐢', '🦎', '🐍', '🐲', '🐉', '🦕', '🦖', '🐳', '🐋', '🐬', '🦭', '🐟', '🐠', '🐡', '🦈', '🐙', '🐚', '🐌', '🦋', '🐛', '🐜', '🐝', '🪲', '🐞', '🦗', '🪳', '🕷', '🕸', '🦂', '🦟', '🪰', '🪱', '🦠', '💐', '🌸', '💮', '🏵', '🌹', '🥀', '🌺', '🌻', '🌼', '🌷', '🌱', '🪴', '🌲', '🌳', '🌴', '🌵', '🌾', '🌿', '☘', '🍀', '🍁', '🍂', '🍃', '🍇', '🍈', '🍉', '🍊', '🍋', '🍌', '🍍', '🥭', '🍎', '🍏', '🍐', '🍑', '🍒', '🍓', '🫐', '🥝', '🍅', '🫒', '🥥', '🥑', '🍆', '🥔', '🥕', '🌽', '🌶', '🫑', '🥒', '🥬', '🥦', '🧄', '🧅', '🍄', '🥜', '🌰', '🍞', '🥐', '🥖', '🫓', '🥨', '🥯', '🥞', '🧇', '🧀', '🍖', '🍗', '🥩', '🥓', '🍔', '🍟', '🍕', '🌭', '🥪', '🌮', '🌯', '🫔', '🥙', '🧆', '🥚', '🍳', '🥘', '🍲', '🫕', '🥣', '🥗', '🍿', '🧈', '🧂', '🥫', '🍱', '🍘', '🍙', '🍚', '🍛', '🍜', '🍝', '🍠', '🍢', '🍣', '🍤', '🍥', '🥮', '🍡', '🥟', '🥠', '🥡', '🦀', '🦞', '🦐', '🦑', '🦪', '🍦', '🍧', '🍨', '🍩', '🍪', '🎂', '🍰', '🧁', '🥧', '🍫', '🍬', '🍭', '🍮', '🍯', '🍼', '🥛', '☕', '🫖', '🍵', '🍶', '🍾', '🍷', '🍸', '🍹', '🍺', '🍻', '🥂', '🥃', '🥤', '🧋', '🧃', '🧉', '🧊', '🥢', '🍽', '🍴', '🥄', '🔪', '🏺', '🌍', '🌎', '🌏', '🌐', '🗺', '🗾', '🧭', '🏔', '⛰', '🌋', '🗻', '🏕', '🏖', '🏜', '🏝', '🏞', '🏟', '🏛', '🏗', '🧱', '🪨', '🪵', '🛖', '🏘', '🏚', '🏠', '🏡', '🏢', '🏣', '🏤', '🏥', '🏦', '🏨', '🏩', '🏪', '🏫', '🏬', '🏭', '🏯', '🏰', '💒', '🗼', '🗽', '⛪', '🕌', '🛕', '🕍', '⛩', '🕋', '⛲', '⛺', '🌁', '🌃', '🏙', '🌄', '🌅', '🌆', '🌇', '🌉', '♨', '🎠', '🎡', '🎢', '💈', '🎪', '🚂', '🚃', '🚄', '🚅', '🚆', '🚇', '🚈', '🚉', '🚊', '🚝', '🚞', '🚋', '🚌', '🚍', '🚎', '🚐', '🚑', '🚒', '🚓', '🚔', '🚕', '🚖', '🚗', '🚘', '🚙', '🛻', '🚚', '🚛', '🚜', '🏎', '🏍', '🛵', '🦽', '🦼', '🛺', '🚲', '🛴', '🛹', '🛼', '🚏', '🛣', '🛤', '🛢', '⛽', '🚨', '🚥', '🚦', '🛑', '🚧', '⚓', '⛵', '🛶', '🚤', '🛳', '⛴', '🛥', '🚢', '✈', '🛩', '🛫', '🛬', '🪂', '💺', '🚁', '🚟', '🚠', '🚡', '🛰', '🚀', '🛸', '🛎', '🧳', '⌛', '⏳', '⌚', '⏰', '⏱', '⏲', '🕰', '🕛', '🕧', '🕐', '🕜', '🕑', '🕝', '🕒', '🕞', '🕓', '🕟', '🕔', '🕠', '🕕', '🕡', '🕖', '🕢', '🕗', '🕣', '🕘', '🕤', '🕙', '🕥', '🕚', '🕦', '🌑', '🌒', '🌓', '🌔', '🌕', '🌖', '🌗', '🌘', '🌙', '🌚', '🌛', '🌜', '🌡', '☀', '🌝', '🌞', '🪐', '⭐', '🌟', '🌠', '🌌', '☁', '⛅', '⛈', '🌤', '🌥', '🌦', '🌧', '🌨', '🌩', '🌪', '🌫', '🌬', '🌀', '🌈', '🌂', '☂', '☔', '⛱', '⚡', '❄', '☃', '⛄', '☄', '🔥', '💧', '🌊', '🎃', '🎄', '🎆', '🎇', '🧨', '✨', '🎈']\n"
     ]
    }
   ],
   "source": [
    "print(emoji_list[3:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3dd4e36-1fbb-4fcd-be93-088355db822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ST = pd.read_csv(\"ST_score.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fd18a3b-806e-4f20-b523-2a46d9af7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ST = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfb4ef02-8d8f-441e-bef3-b94d1feecb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element1</th>\n",
       "      <th>element2</th>\n",
       "      <th>new_element</th>\n",
       "      <th>score</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>liquid</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "      <td>wind</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water</td>\n",
       "      <td>earth</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>fire</td>\n",
       "      <td>flame</td>\n",
       "      <td>1</td>\n",
       "      <td>Water can be extinguished by fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>liquid</td>\n",
       "      <td>mixture</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>air</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>climate</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>drainage</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          element1     element2  new_element  score  \\\n",
       "0            water        water       liquid      2   \n",
       "1            water         wind         rain      2   \n",
       "2            water        earth  groundwater      2   \n",
       "3            water         fire        flame      1   \n",
       "4            water       liquid      mixture      2   \n",
       "..             ...          ...          ...    ...   \n",
       "200  precipitation   irrigation         rain      2   \n",
       "201  precipitation  agriculture   irrigation      2   \n",
       "202  precipitation          air      weather      2   \n",
       "203  precipitation   atmosphere      climate      2   \n",
       "204  precipitation     drainage         rain      2   \n",
       "\n",
       "                                 notes  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3    Water can be extinguished by fire  \n",
       "4                                  NaN  \n",
       "..                                 ...  \n",
       "200                                NaN  \n",
       "201                                NaN  \n",
       "202                                NaN  \n",
       "203                                NaN  \n",
       "204                                NaN  \n",
       "\n",
       "[199 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88171976-cd19-4f7e-9253-3b6f23671216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = df_ST['new_element'].nunique()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5419e470-1af8-45eb-bedc-b8b044c69aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W2V = pd.read_csv(\"W2V_score.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a75ace9-cfa4-4ff3-9849-ffbcae0625d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W2V = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c206d07-89c2-4a6d-8726-0b9f708c0f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element1</th>\n",
       "      <th>element2</th>\n",
       "      <th>new_element</th>\n",
       "      <th>score</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>water</td>\n",
       "      <td>liquid</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "      <td>wind</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water</td>\n",
       "      <td>earth</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>fire</td>\n",
       "      <td>flame</td>\n",
       "      <td>1</td>\n",
       "      <td>Water can be extinguished by fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>liquid</td>\n",
       "      <td>mixture</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>air</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>climate</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>precipitation</td>\n",
       "      <td>drainage</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          element1     element2  new_element  score  \\\n",
       "0            water        water       liquid      2   \n",
       "1            water         wind         rain      2   \n",
       "2            water        earth  groundwater      2   \n",
       "3            water         fire        flame      1   \n",
       "4            water       liquid      mixture      2   \n",
       "..             ...          ...          ...    ...   \n",
       "200  precipitation   irrigation         rain      2   \n",
       "201  precipitation  agriculture   irrigation      2   \n",
       "202  precipitation          air      weather      2   \n",
       "203  precipitation   atmosphere      climate      2   \n",
       "204  precipitation     drainage         rain      2   \n",
       "\n",
       "                                 notes  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3    Water can be extinguished by fire  \n",
       "4                                  NaN  \n",
       "..                                 ...  \n",
       "200                                NaN  \n",
       "201                                NaN  \n",
       "202                                NaN  \n",
       "203                                NaN  \n",
       "204                                NaN  \n",
       "\n",
       "[199 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ca23558-3aac-4ea0-9e50-ebcc4446cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = df_W2V['new_element'].nunique()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c812b27-074d-4efb-a1e9-8b81e28d1ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
